\documentclass[12pt]{article}

% Essential packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathrsfs}
\usepackage{geometry}
\usepackage{hyperref}

% Geometry settings
\geometry{a4paper, margin=1in}

% Hyperref settings
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

% Theorem environments
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{axiom}[theorem]{Axiom}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

% Math operators
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\Enc}{Enc}
\DeclareMathOperator{\Dec}{Dec}
\DeclareMathOperator{\Aut}{Aut}

% Title information
\title{Finite-Information Universe\\
and Parameter Vector $\Theta$:\\
Entropy Bounds, Axiomatization\\
and Quantum Cellular Automaton Source Code Length}
\author{Haobo Ma$^1$ \and Wenlin Zhang$^2$\\
\small $^1$Independent Researcher\\
\small $^2$National University of Singapore}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Standard picture of continuous spacetime and quantum field theory suggests: mathematically specifying a complete ``universe'' object seems to require infinitely much information---infinitely many spacetime points, infinitely many degrees of freedom at each point, initial conditions as infinite-precision real-valued functions. This ``infinite-information universe'' picture faces fundamental difficulties both physically and information-theoretically. On other hand, black hole entropy bounds, holographic entropy bounds and quantum computation limits jointly strongly suggest: within finite energy and finite spacetime region, physically distinguishable information amount has finite upper bound.

Building on solid foundation given by Bekenstein entropy bound, Bousso holographic bound and Lloyd computation limit, this paper introduces ``finite information capacity'' axiom: exists finite constant $I_{\max} < \infty$ such that physically distinguishable total information amount of entire observable universe does not exceed $I_{\max}$. Under this axiom, we prove: ``universe'' can be viewed as object completely specified by finite bit string $\Theta$, give systematic parameter vector decomposition

$$
\Theta = (\Theta_{\mathrm{str}},\Theta_{\mathrm{dyn}},\Theta_{\mathrm{ini}}),
$$

respectively describing spacetime/lattice/topological structure, quantum cellular automaton (QCA) dynamics rules and initial quantum state.

In concrete Dirac-type QCA universe model, we constructively give information complexity upper bound: under strong translation symmetry, fixed gate set and finite-precision discretization assumptions, encoding lengths of structural parameters, dynamical parameters, initial state parameters can be controlled at order $\mathcal{O}(10^2)$, $\mathcal{O}(10^3)$, $\mathcal{O}(10^2\text{--}10^3)$ bits respectively, thus obtaining typical source code information amount estimate

$$
I_{\mathrm{param}}(\Theta) = |\Theta_{\mathrm{str}}| + |\Theta_{\mathrm{dyn}}| + |\Theta_{\mathrm{ini}}| \sim 10^3 \text{ bits},
$$

far smaller than maximum entropy $S_{\max}(\Theta) \sim 10^{90\text{--}122}$ bits estimated from universe horizon area. We further prove information--entropy inequality

$$
I_{\mathrm{param}}(\Theta) + S_{\max}(\Theta) \le I_{\max},
$$

showing ``small source code'' and ``giant entropy universe'' compatible under finite information capacity axiom.

To address intuitive question ``why can extremely small initial data evolve into extremely high complexity universe'', this paper analyzes evolutionary structure of QCA universe from dynamical system and quantum superposition perspective: given short parameter vector $\Theta$, entire universe history viewable as finite program linear unitary evolution in high-dimensional Hilbert combinatorial space; quantum superposition is not ``brute force enumeration of all permutation combinations'', but realizes amplitude and phase unified update and interference on ``linear envelope of all classical combinations''. This explains why ``source code universe'' with finite algorithmic complexity can macroscopically present complex structure approaching maximum entropy.

Finally, we discuss structure on parameter space $\mathcal{M}_\Theta$, finite information inequality constraints on lattice number and unit Hilbert dimension, and how anthropic principle and physical constraints compress possible universe set to extremely small realizable subset under given finite $I_{\max}$ and parameter vector $\Theta$.
\end{abstract}

\noindent\textbf{Keywords:} Finite information; Entropy bounds; Parameter vector; Quantum cellular automaton; Source code length; Bekenstein bound; Holographic principle; Kolmogorov complexity

\section{Introduction: From ``Infinite-Information Universe'' to ``Finite-Information Universe''}

In standard continuous spacetime and quantum field theory picture, complete ``universe state'' usually viewed as following object:

\begin{enumerate}
\item Lorentz metric $g_{\mu\nu}(x)$ on four-dimensional manifold $M$, giving metric tensor at each spacetime point $x$;

\item Quantum field $\hat{\Phi}_a(x)$ on $M$, initial condition of each mode needs to specify one real function;

\item Vacuum/thermal state/fluctuation configuration on some initial Cauchy hypersurface.
\end{enumerate}

These objects mathematically often rely on uncountably infinite-dimensional function spaces, whose ``complete precise specification'' seems to require infinitely many numbers, i.e., infinite information amount. This brings several difficulties:

\begin{itemize}
\item Physically, hard to explain how object requiring infinite information to specify can be compatible with real universe of finite energy and finite volume;

\item Information-theoretically, ``universe'' that cannot be encoded in any finite-length bit string hard to reconcile with computational realizability;

\item Philosophically, whether ``unrepresentable'' universe has testable physical meaning is questionable.
\end{itemize}

Meanwhile, black hole thermodynamics and holographic entropy bounds give strongly opposite suggestion: within finite radius and energy region, containable entropy has strict upper bound; holographic bound further points out, for ``lightsheet'' associated with some closed spatial surface $\Sigma$, total entropy that can be transferred through any means does not exceed $A(\Sigma)/4G\hbar$, where $A(\Sigma)$ is area of $\Sigma$. These results jointly point to simple conclusion: \textbf{under finite volume and finite energy, physically distinguishable total information amount is finite}.

This paper adds one axiom on this physical intuition: physically distinguishable total information amount of entire observable universe has finite upper bound $I_{\max}$. Under this axiom, ``infinite-information universe'' picture replaced by ``finite-information universe'': universe can be completely specified by some finite-length bit string $\Theta$, we call it ``universe parameter vector'' or ``source code''.

To concretize this idea, we choose quantum cellular automaton (QCA) as discrete universe model carrier, construct parameterized universe object $\mathfrak{U}(\Theta)$, systematically characterize structure, dynamics and initial state triple decomposition of $\Theta$, give upper bound estimate of source code information amount $I_{\mathrm{param}}(\Theta)$, derive information--entropy inequality $I_{\mathrm{param}}(\Theta) + S_{\max}(\Theta) \le I_{\max}$, and explain naturalness of ``small source code, large complexity'' in quantum superposition and dynamical system language.

\section{Physical Entropy Bounds and Finite Information Capacity Axiom}

\subsection{Unified View of Physical Entropy Bounds}

Consider spherical region of radius $R$, energy $E$, containing some physical system. Bekenstein entropy bound gives upper bound on entropy storable in this region

$$
S \le \frac{2\pi R E}{\hbar c},
$$

showing under finite energy and finite linear dimension, entropy cannot increase indefinitely. For situation including gravity, if region forms black hole, Bekenstein--Hawking formula shows black hole entropy

$$
S_{\mathrm{BH}} = \frac{A_{\mathrm{hor}}}{4 G \hbar},
$$

connecting entropy with horizon area. Holographic entropy bound further points out, for any spatial surface $\Sigma$, along contracting null lightsheet direction, entropy flux $S_{\mathrm{lightsheet}}$ passing through this lightsheet satisfies

$$
S_{\mathrm{lightsheet}} \le \frac{A(\Sigma)}{4 G \hbar}.
$$

On other hand, Lloyd and Margolus--Levitin type computation limit theorem points out: quantum system supported by energy $E$, maximum number of logical operations $N_{\mathrm{ops}}$ executable within time interval $T$ has upper bound

$$
N_{\mathrm{ops}} \le \frac{2 E T}{\pi \hbar},
$$

showing within finite energy and finite time, computational resources also finite.

Although these inequalities have different forms and applicability conditions, in this work we only extract their common core: \textbf{finite energy, finite spacetime region and finite evolution time $\Rightarrow$ distinguishable information finite}.

\subsection{Physically Distinguishable Information and Equivalence Classes}

To formalize ``distinguishable information'', we introduce following concept. Let $\mathcal{S}$ be set of all possible states of some physical system, each state represented by density operator $\rho$. Given family of feasible measurements $\{A_\alpha\}$ and measurement precision lower bound $\epsilon$, we say $\rho_1,\rho_2 \in \mathcal{S}$ physically distinguishable if and only if exists some $A_\alpha$ such that

$$
\bigl| \tr(\rho_1 A_\alpha) - \tr(\rho_2 A_\alpha) \bigr| > \epsilon.
$$

Further define equivalence relation $\rho_1 \sim \rho_2$ if for all feasible measurements and precision requirements, both indistinguishable. Thus full set $\mathcal{S}$ partitioned into physically distinguishable state equivalence classes, denoted $\mathcal{S} / \sim$. We define ``physically distinguishable information amount'' of this system as

$$
I_{\mathrm{phys}} := \log_2 \bigl| \mathcal{S} / \sim \bigr|.
$$

Under physical premises of Bekenstein and Bousso entropy bounds, corresponding $I_{\mathrm{phys}}$ for various concrete systems (such as finite-radius sphere, finite horizon universe) necessarily finite. We elevate this finiteness to universe-level axiom.

\subsection{Finite Information Capacity Axiom and Encoding Map}

\begin{axiom}[Finite Information Capacity]
\label{axiom:finite-info}
Exists finite constant $I_{\max} < \infty$ such that physically distinguishable information amount of entire observable universe satisfies

$$
I_{\mathrm{phys}}(\text{Universe}) \le I_{\max}.
$$
\end{axiom}

From this axiom, can immediately introduce abstract encoding map

$$
\Enc : \mathfrak{U}_{\mathrm{phys}} \to \{0,1\}^{\le I_{\max}},
$$

where $\mathfrak{U}_{\mathrm{phys}}$ represents all physically distinguishable ``universe objects'', $\{0,1\}^{\le I_{\max}}$ set of bit strings of length not exceeding $I_{\max}$. We denote encoding of some concrete universe as

$$
\Theta := \Enc(\mathfrak{U}) \in \{0,1\}^{\le I_{\max}},
$$

call $\Theta$ ``parameter vector'' or ``source code'' of this universe.

Conversely, exists some decoding map $\Dec$ such that $\Dec(\Theta)$ gives universe physically equivalent to $\mathfrak{U}$. Thus, under finite information capacity axiom, ``universe'' can be viewed as decoding result of some finite bit string.

\section{Parameterized Representation of Universe and QCA Universe Model}

\subsection{Abstract Structure of Universe Object}

Under modern field theory and operator algebra framework, universe can be abstracted as categorical structure $\mathfrak{U}$, including spacetime manifold, metric, quantum fields, local algebra, base state, etc. This work does not need this complete complexity, but only retains components directly related to information complexity.

For this, we consider class of discretized universe models, whose basic composition as follows:

\begin{enumerate}
\item Lattice site set $\Lambda$, can be finite or locally finite;

\item Each lattice site $x \in \Lambda$ has unit Hilbert space $\mathcal{H}_{\mathrm{cell}}$, dimension $d_{\mathrm{cell}}$;

\item Global Hilbert space $\mathcal{H} = \bigotimes_{x\in\Lambda} \mathcal{H}_{\mathrm{cell}}$;

\item Quasi-local $C^\ast$ algebra $\mathcal{A} \subset \mathcal{B}(\mathcal{H})$ generated by local operators;

\item Time evolution automorphism group $\alpha:\mathbb{Z}\to \Aut(\mathcal{A})$, describing discrete time update;

\item Initial state $\omega_0$, i.e., positive normalized linear functional on $\mathcal{A}$.
\end{enumerate}

We denote such object as

$$
\mathfrak{U} = (\Lambda,\mathcal{H}_{\mathrm{cell}},\mathcal{A},\alpha,\omega_0).
$$

\subsection{Quantum Cellular Automaton as Underlying Model}

To concretize $\alpha$, we adopt quantum cellular automaton (QCA) framework: time step $n\to n+1$ realized by some local unitary operator $U$, i.e., for all local operators $A \in \mathcal{A}$ have

$$
\alpha(A) = U^\dagger A U.
$$

Locality requirement means $U$'s action has finite propagation within causal light cone, i.e., exists finite radius $r$ such that operator $A$ acting only on some region $R$ expands only to $r$ neighborhood of $R$ after one evolution step.

In this work, we do not discuss specific classification of QCA, but only use following fact: given appropriate local gate set and lattice structure, QCA can approximate free Dirac field and more general low-energy field theory in continuous limit. Thus, natural to represent universe object as parameterized QCA universe

$$
\mathfrak{U}(\Theta) = \bigl(\Lambda(\Theta),\mathcal{H}_{\mathrm{cell}}(\Theta),\mathcal{A}(\Theta),\alpha_\Theta,\omega_0^\Theta\bigr),
$$

where all components determined by parameter vector $\Theta$.

This modeling choice not necessarily derived from finite information axiom, but as representative class of discrete universe scheme. Finite information axiom requires existence of some class of finite-dimensional, finitely-generated structures; QCA model has good locality and computational realizability in this class of structures, thus natural candidate.

\section{Triple Decomposition of Parameter Vector $\Theta$}

\subsection{Structure of Parameter Space}

After giving QCA universe framework, role of parameter vector $\Theta$ can be naturally distinguished into three categories:

\begin{enumerate}
\item ``Structural parameters'' determining lattice structure and topology;

\item ``Dynamical parameters'' determining local evolution rules;

\item ``Initial state parameters'' determining initial quantum state structure.
\end{enumerate}

Formally write

$$
\Theta = (\Theta_{\mathrm{str}},\Theta_{\mathrm{dyn}},\Theta_{\mathrm{ini}}),
$$

where each component has independent information content.

\subsection{Structural Parameters $\Theta_{\mathrm{str}}$}

Structural parameters specify lattice topology and local dimension:

\begin{itemize}
\item Lattice dimension $d_{\mathrm{lat}}$ (e.g., 1D, 2D, 3D, 4D);
\item Lattice size $N_{\mathrm{sites}}$ (or characteristic scale under periodic boundary conditions);
\item Unit Hilbert dimension $d_{\mathrm{cell}}$;
\item Topological data (e.g., boundary condition type, twist, defect);
\item Symmetry group labels.
\end{itemize}

Under strong translation symmetry assumption, structural parameters can be extremely compact. For example, three-dimensional cubic lattice with periodic boundary, need only specify:

$$
\Theta_{\mathrm{str}} = (d_{\mathrm{lat}}=3, N_{\mathrm{linear}}, d_{\mathrm{cell}}, \text{boundary type}).
$$

If $N_{\mathrm{linear}} \sim 10^{26}$ (cosmological scale lattice spacing), encode as 90-bit integer; $d_{\mathrm{cell}} \sim 10$ encode as 4 bits; boundary condition type several bits. Total

$$
|\Theta_{\mathrm{str}}| \sim \mathcal{O}(10^2) \text{ bits}.
$$

\subsection{Dynamical Parameters $\Theta_{\mathrm{dyn}}$}

Dynamical parameters specify QCA local gates. Typical setting: choose finite universal gate set $\mathcal{G} = \{G_1,\dots,G_K\}$, each gate acts on limited lattice sites. Update operator $U$ written as

$$
U = \prod_{\text{layers}} \prod_{x\in\text{layer}} G_{i_x}(x),
$$

where $i_x \in \{1,\dots,K\}$ gate index at position $x$.

If gate set $\mathcal{G}$ fixed (analogous to ``elementary particles and interaction types'' given by Standard Model), then dynamical parameters only need specify gate sequence arrangement. Under strong symmetry (translation invariance, gauge symmetry), number of independent parameters drastically reduced.

Estimate: if gate library size $K \sim 10$, need $\log_2 K \sim 4$ bits per gate; if update requires $L \sim 10^2$ layers, total independent gates $\sim 10^3$, then

$$
|\Theta_{\mathrm{dyn}}| \sim \mathcal{O}(10^3) \text{ bits}.
$$

Additionally considering gate parameter fine-tuning (e.g., coupling constant angles), if each parameter needs 10-bit precision, still within kilobit order.

\subsection{Initial State Parameters $\Theta_{\mathrm{ini}}$}

Initial state $\omega_0$ can be pure state or mixed state. Simplest case, pure state

$$
|\psi_0\rangle \in \mathcal{H} = \bigotimes_{x\in\Lambda} \mathbb{C}^{d_{\mathrm{cell}}}.
$$

Dimension of $\mathcal{H}$ is $d_{\mathrm{cell}}^{N_{\mathrm{sites}}}$, naively seems to need exponentially many parameters to specify $|\psi_0\rangle$. However, under following assumptions, initial state encoding length can be controlled:

\begin{itemize}
\item Initial state has simple tensor product structure or low entanglement (e.g., vacuum state, coherent state);
\item Initial fluctuation describable by finite parameter family (e.g., Gaussian random field with limited modes);
\item Certain conservation laws or symmetry constraints reduce effective degrees of freedom.
\end{itemize}

Concrete estimate: if initial state is tensor product of single-site states plus small perturbation, perturbation expansion to finite order, number of independent parameters $\sim 10^2\text{--}10^3$. If each parameter 10-bit precision,

$$
|\Theta_{\mathrm{ini}}| \sim \mathcal{O}(10^2\text{--}10^3) \text{ bits}.
$$

For highly entangled initial states, encoding length may be larger, but under finiteness axiom, must remain within finite $I_{\max}$ range.

\subsection{Total Source Code Length Estimate}

Combining above three parts, obtain total parameter information amount

$$
I_{\mathrm{param}}(\Theta) = |\Theta_{\mathrm{str}}| + |\Theta_{\mathrm{dyn}}| + |\Theta_{\mathrm{ini}}| \sim \mathcal{O}(10^3) \text{ bits}.
$$

This is extremely compact encoding: kilobit-level information can specify entire universe structure, dynamics and initial state.

\section{Information--Entropy Inequality and Compatibility}

\subsection{Maximum Entropy Estimate}

For observable universe, horizon area $A_{\mathrm{horizon}} \sim (10^{26}\text{ m})^2 \sim 10^{52}\text{ m}^2$, Planck area $\ell_{\mathrm{Pl}}^2 \sim 10^{-70}\text{ m}^2$, thus

$$
S_{\max} \sim \frac{A_{\mathrm{horizon}}}{4\ell_{\mathrm{Pl}}^2} \sim 10^{122} \text{ bits}.
$$

This is astronomically large entropy upper bound.

\subsection{Information--Entropy Inequality}

\begin{proposition}[Information--Entropy Inequality]
\label{prop:info-entropy-ineq}
Under finite information capacity axiom, universe parameter information amount and maximum entropy satisfy

$$
I_{\mathrm{param}}(\Theta) + S_{\max}(\Theta) \le I_{\max}.
$$
\end{proposition}

\begin{proof}
Total physically distinguishable information of universe includes:

\begin{enumerate}
\item Source code information: $I_{\mathrm{param}}(\Theta)$;
\item Macrostate entropy: $S_{\max}(\Theta)$, representing distinguishable microscopic configurations under given structure.
\end{enumerate}

By axiom, total information $\le I_{\max}$, thus inequality holds.
\end{proof}

\subsection{Compatibility of Small Source Code and Large Entropy}

Proposition~\ref{prop:info-entropy-ineq} shows: even if $I_{\mathrm{param}}(\Theta) \sim 10^3$ extremely small, can still accommodate $S_{\max}(\Theta) \sim 10^{122}$, only requires $I_{\max} \ge 10^{122}$.

This resolves apparent paradox: ``How can small source code generate high-entropy universe?'' Answer: source code specifies \emph{rules}, not all details; entropy measures \emph{state space size}, not rule complexity. Quantum superposition and dynamical evolution allow finite rules to generate exponentially large state space.

\section{Quantum Superposition and Evolution of Complexity}

\subsection{Dynamical System Perspective}

Given parameter vector $\Theta$, universe history is finite program execution:

$$
|\psi(n)\rangle = U^n|\psi_0\rangle,
$$

where $U$ and $|\psi_0\rangle$ determined by $\Theta$. Although program finite, state space $\mathcal{H}$ exponentially large, allowing system to explore high-complexity region.

\subsection{Quantum Superposition vs. Classical Enumeration}

Key difference: quantum evolution not ``enumerating all classical configurations'', but ``coherent superposition in linear space spanned by all configurations''. State at time $n$

$$
|\psi(n)\rangle = \sum_{\text{configs}} c_{\text{config}}(n) |\text{config}\rangle,
$$

where coefficients $c_{\text{config}}(n)$ computed by unitary matrix product, not independent enumeration. This explains how finite algorithm can generate exponentially many interfering amplitudes.

\subsection{Entropy Growth and Thermalization}

Through local interactions, initially low-entanglement state gradually thermalizes, entropy approaches maximum $S_{\max}$. This not contradiction with finite source code, but result of dynamical evolution: source code specifies \emph{evolution law}, thermalization is \emph{consequence of evolution}.

\section{Parameter Space Structure and Anthropic Constraints}

\subsection{Parameter Space Manifold}

All possible $\Theta$ form parameter space

$$
\mathcal{M}_\Theta = \mathcal{M}_{\mathrm{str}} \times \mathcal{M}_{\mathrm{dyn}} \times \mathcal{M}_{\mathrm{ini}}.
$$

Dimension $\dim \mathcal{M}_\Theta \sim 10^3$. However, only extremely small subset physically realizable.

\subsection{Physical Constraints}

Various physical requirements constrain parameter space:

\begin{itemize}
\item Consistency with observed low-energy physics (Standard Model);
\item Cosmological evolution matching observations;
\item Stability and causality constraints;
\item Thermodynamic consistency.
\end{itemize}

These constraints drastically reduce viable parameter region.

\subsection{Anthropic Principle}

Further, anthropic principle requires universe parameters allow emergence of complex structures (observers). This adds additional selection mechanism, possibly reducing realizable universe set to countable or even unique.

\section{Discussion and Outlook}

This work shows: under finite information capacity axiom derived from physical entropy bounds, entire universe can be specified by finite bit string $\Theta$. Through QCA universe model, we systematically decompose $\Theta$ into structural, dynamical and initial state parameters, giving source code length estimate $\sim 10^3$ bits.

Information--entropy inequality $I_{\mathrm{param}}(\Theta) + S_{\max}(\Theta) \le I_{\max}$ shows small source code compatible with large entropy. Quantum superposition and dynamical evolution explain how finite rules generate exponentially complex phenomena.

This finite-information universe picture has profound implications:

\begin{enumerate}
\item Philosophically: universe ``writable'' and ``simulable'';
\item Physically: no continuous infinity, only discrete approximations;
\item Information-theoretically: universe information content finite, computable.
\end{enumerate}

Future directions include:

\begin{itemize}
\item Refine parameter encoding schemes;
\item Construct explicit QCA models matching observations;
\item Explore minimal source code length lower bounds;
\item Connect with quantum gravity and holography.
\end{itemize}

\appendix

\section{Bekenstein Bound and Holographic Principle}

This appendix reviews Bekenstein entropy bound and holographic entropy bound.

\subsection{Bekenstein Entropy Bound}

For system of energy $E$ confined to region of size $R$, Bekenstein bound states

$$
S \le \frac{2\pi R E}{\hbar c}.
$$

This bound derived from thermodynamic considerations and generalized second law including black holes.

\subsection{Holographic Entropy Bound}

Bousso's covariant entropy bound: for any lightsheet $\mathcal{L}$ starting from spatial surface $\Sigma$,

$$
S(\mathcal{L}) \le \frac{A(\Sigma)}{4G\hbar}.
$$

This generalizes black hole entropy formula to arbitrary causal structures.

\section{QCA Universality and Continuous Limit}

This appendix discusses how QCA approximates continuous field theory.

\subsection{Dirac QCA Model}

One-dimensional Dirac QCA with gates

$$
U = \prod_x U_{\mathrm{coin}}(x) U_{\mathrm{shift}},
$$

in continuum limit reproduces Dirac equation. Extension to 3+1 dimensions possible with appropriate gate design.

\subsection{Convergence Rate}

Discretization error $\mathcal{O}(a)$ where $a$ lattice spacing. For cosmological observations, $a \sim \ell_{\mathrm{Pl}}$ makes error negligible.

\end{document}
